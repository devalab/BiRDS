# %%
# Some constants that will be required
# ALWAYS RUN THIS CODE CELL
import os
from IPython import get_ipython

data_dir = os.path.abspath("../data/scPDB")
raw_dir = os.path.join(data_dir, "raw")
pssm_dir = os.path.join(data_dir, "pssm")
splits_dir = os.path.join(data_dir, "splits")
preprocessed_dir = os.path.join(data_dir, "preprocessed")


# %%
# Download the scPDB dataset and extract the dataset in "data/scPDB/raw"
resource = "http://bioinfo-pharma.u-strasbg.fr/scPDB/ressources/2016/scPDB.tar.gz"
# !aria2c -c -x 8 -s 8 -d $data_dir $resource --out 'scPDB.tar.gz'
# !tar xvzf ../data/scPDB/scPDB.tar.gz -C ../data/scPDB/raw/


# %%
# For 10-fold Cross Validation, we will use the splits that were generated by https://arxiv.org/abs/1904.06517
resource = "https://gitlab.com/cheminfIBB/kalasanty/-/archive/master/kalasanty-master.tar.gz?path=data"
# !aria2c -c -x 8 -s 8 -d "../data/scPDB" $resource --out 'kalasanty-master-data.tar.gz'
# !tar xvzf ../data/scPDB/kalasanty-master-data.tar.gz -C ../data/scPDB/


# %%
# For sequence-based prediction, we need to use RCSB FASTA files
# import urllib.request

# for folder in sorted(os.listdir(raw_dir)):
#     pdb_id = folder[:4]
#     print(pdb_id)

#     fasta_save = os.path.join(raw_dir, folder, "sequence.fasta")
#     if not os.path.exists(fasta_save):
#         try:
#             urllib.request.urlretrieve(
#                 "https://www.rcsb.org/pdb/download/downloadFastaFiles.do?structureIdList="
#                 + pdb_id
#                 + "&compressionType=uncompressed",
#                 fasta_save,
#             )
#         except:
#             print("Err: fasta " + pdb_id)


# %%
# Check whether downloaded sequence files are correct
# A few of the PDB files have been obseleted and hence will have to manually download them
# I wrote down the manual mapping of the pdb id's but seem to have lost it
# But they can easily be found out from data/obseleted.txt file

# for folder in sorted(os.listdir(raw_dir)):
#     pdb_id = folder[:4]
#     fasta_save = os.path.join(raw_dir, folder, "sequence.fasta")
#     with open(fasta_save, "r") as f:
#         line = f.readline()
#         if line[0] != ">":
#             print("Err: FASTA " + folder)


# %%
# Let us reindex protein.mol2 and site.mol2 and convert to PDB format
# So that they can be imported using biopython
# Also let us write fasta sequence for the chains in protein.mol2 files
# Download NWalign.py
# https://zhanglab.ccmb.med.umich.edu/NW-align/NWalign.py (Make small changes for Python3 compatibility)
from mol2 import Mol2

for folder in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, folder)
    reindexed_site = os.path.join(pre, "reindexed_site.pdb")
    if os.path.exists(reindexed_site):
        continue
    print(folder)
    # if folder == "1a5s_1":
    #     exit(1)
    fasta = os.path.join(pre, "sequence.fasta")
    prot_mol = Mol2(os.path.join(pre, "protein.mol2"))
    site_mol = Mol2(os.path.join(pre, "site.mol2"))
    reindexed_prot = os.path.join(pre, "reindexed_protein.pdb")
    prot_mol.reindex(fasta)
    site_mol.subst_df["reindex_id"] = 0
    for i, record in enumerate(site_mol.subst_df[["subst_name", "chain"]].values):
        site_mol.subst_df.at[i, "reindex_id"] = prot_mol.subst_df[
            (prot_mol.subst_df["subst_name"] == record[0])
            & (prot_mol.subst_df["chain"] == record[1])
        ]["reindex_id"]
    prot_mol.write_pdb(reindexed_prot)
    site_mol.write_pdb(reindexed_site)

    with open(fasta, "r") as f:
        header = f.readline()
        while 1:
            chain_id = header[6:7]
            sequence = ""
            line = f.readline()
            while line != "" and line is not None and line[0] != ">":
                sequence += line.strip()
                line = f.readline()
            if chain_id in prot_mol.sequences:
                with open(os.path.join(pre, chain_id + ".fasta"), "w") as hlp:
                    hlp.write(header)
                    hlp.write(sequence + "\n")
            if line == "" or line is None:
                break
            header = line


# %%
# In case you want to delete the generated fasta files from the above cell, use this
# from glob import glob
# for file in sorted(os.listdir(raw_dir)):
#     for fasta in glob(os.path.join(raw_dir, file.strip(), "?.fasta")):
#         os.remove(fasta)

# %%
# The fasta files generated will have a lot of common sequences
# To speed up MSA generation, let us create a unique file that has common sequences
# Then we can generate the MSAs for only the first chain in every line
from collections import defaultdict

sequences = defaultdict(list)
for file in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, file.strip())
    for fasta in sorted(os.listdir(pre)):
        if fasta[2:] != "fasta":
            continue
        chain_id = fasta[0]
        with open(os.path.join(pre, fasta)) as f:
            f.readline()
            sequence = f.readline().strip()
            # This choice was made so that rsync would work much better and easier
            sequences[sequence].append(file + "/" + chain_id + "*")

keys = list(sequences.keys())

with open(os.path.join(data_dir, "unique"), "w") as f:
    for key in keys:
        line = ""
        for chain_id in sequences[key]:
            line += chain_id + " "
        f.write(line[:-1] + "\n")


# %%
# MSAs need to be generated for the fasta files
# Refer to https://github.com/crvineeth97/msa-generator


# %%
# MAKING OF .npz FILES FROM HERE
# Download NWalign.py, pdb2fasta.py and reindex_pdb.py
# https://zhanglab.ccmb.med.umich.edu/NW-align/NWalign.py (Make small changes for Python3 compatibility)
# https://zhanglab.ccmb.med.umich.edu/reindex_pdb/reindex_pdb.py (Make changes to allow for reindexing specific chains and also to replace celenocysteine, "U" with "X")
# https://zhanglab.ccmb.med.umich.edu/reindex_pdb/pdb2fasta.py (Almost the same)
# Let us preprocess ALL the available data and create .npz files which contain pdb_id, chain_id, sequence, length, labels
# The following will fail reindexing
# 1m1d_1 D, 2xbm_4 E, 2xbm_4 F, 3h9j_6 E, 3h9j_6 F, 3h9j_6 H, 4mfp_1 B, 4mfq_1 B, 4oav_2 A, 4oav_2 C, 7kme_1 J because they are not protein chains
# %debug
# from IPython.core.debugger import set_trace
import warnings
from time import time

import numpy as np

from Bio import BiopythonWarning
from Bio.PDB import PDBParser, is_aa
from rdkit import Chem
from rdkit.Chem.rdMolTransforms import ComputeCentroid

warnings.simplefilter("ignore", BiopythonWarning)
parser = PDBParser()


def initialize_protein_info(pdb_id_struct, chain_id):
    pre = os.path.join(raw_dir, pdb_id_struct)
    protein = {}
    protein["structure"] = parser.get_structure(
        pdb_id_struct, os.path.join(pre, "reindexed_protein.pdb")
    )

    protein["residues"] = []
    for res in protein["structure"][0][chain_id]:
        id = res.get_id()
        if is_aa(res, standard=False) and id[0] == " ":
            protein["residues"].append(res)

    protein["sequence"] = ""
    with open(os.path.join(pre, chain_id + ".fasta")) as f:
        line = f.readline()
        line = f.readline()
        while line != "" and line is not None:
            protein["sequence"] += line.strip()
            line = f.readline()
    return protein


def initialize_ligand_info(pdb_id_struct):
    pre = os.path.join(raw_dir, pdb_id_struct)
    ligand = {}
    ligand["supplier"] = Chem.SDMolSupplier(
        os.path.join(pre, "ligand.sdf"), sanitize=False
    )
    assert len(ligand["supplier"]) == 1
    ligand["supplier"] = ligand["supplier"][0]
    assert ligand["supplier"].GetNumConformers() == 1
    ligand["coords"] = ligand["supplier"].GetConformer().GetPositions()
    ligand["num_atoms"] = ligand["supplier"].GetNumAtoms()
    assert ligand["num_atoms"] == len(ligand["coords"])
    ligand["atom_types"] = np.array(
        [atom.GetSymbol() for atom in ligand["supplier"].GetAtoms()]
    )
    return ligand


def find_residues_in_contact(protein, ligand):
    """
    Returns a numpy 1D array where a 1 represents that the amino acid is in
    contact with the ligand
    """
    labels = np.zeros(len(protein["sequence"]))
    for residue in protein["residues"]:
        res_ind = residue.get_id()[1] - 1
        for atom in residue.get_atoms():
            if atom.get_fullname()[1] == "H":
                continue
            for i in range(ligand["num_atoms"]):
                if ligand["atom_types"][i] == "H":
                    continue
                # We are considering the ligand to be in contact with the AA
                # if the distance between them is within 5A
                if np.linalg.norm(atom.get_coord() - ligand["coords"][i]) <= 5.0:
                    labels[res_ind] = 1
                    break
            # We know that the residue is in contact with ligand
            # So go to the next residue
            if labels[res_ind]:
                break
    return labels


def get_protein_ligand_dist(protein, ligand):
    # Considering distance between ligand centroid and CB/CA atom of AA
    centroid = ComputeCentroid(ligand["supplier"].GetConformer())
    centroid = np.array([centroid.x, centroid.y, centroid.z])
    dist = np.full(len(protein["sequence"]), 1e6)
    for residue in protein["residues"]:
        res_ind = residue.get_id()[1] - 1
        if residue.has_id("CB"):
            atom_type = "CB"
        elif residue.has_id("CA"):
            atom_type = "CA"
        else:
            continue
        dist[res_ind] = np.linalg.norm(residue[atom_type].get_coord() - centroid)
    return dist


def get_distance_map_true(protein, atom_type):
    length = len(protein["sequence"])
    num_residues = len(
        protein["residues"]
    )  # Might be different from length because of missing residues
    # Don't use np.inf, use a large number
    distance_map = np.full((length, length), 1e6)  # Initialize to infinite distance
    for ind1 in range(num_residues):
        res1 = protein["residues"][ind1]
        if res1.has_id(atom_type) is False:
            continue
        res1_ind = res1.get_id()[1] - 1
        for ind2 in range(ind1 + 1, num_residues):
            res2 = protein["residues"][ind2]
            if res2.has_id(atom_type) is False:
                continue
            res2_ind = res2.get_id()[1] - 1
            dist = np.linalg.norm(
                res1[atom_type].get_coord() - res2[atom_type].get_coord()
            )
            distance_map[res1_ind][res2_ind] = dist
            distance_map[res2_ind][res1_ind] = dist
    np.fill_diagonal(distance_map, 0.0)
    return distance_map


if not os.path.exists(preprocessed_dir):
    os.mkdir(preprocessed_dir)

process_time = 0
write_time = 0
for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, pdb_id_struct)
    if not os.path.exists(os.path.join(pre, "downloaded.pdb")):
        print("Downloaded PDB does not exist for %s" % pdb_id_struct)
        continue
    process_time_start = time()
    for file in sorted(os.listdir(pre)):
        # Get only the chain fasta sequences
        if file[2:] != "fasta":
            continue
        chain_id = file[0]

        # If our preprocessed file exists, continue
        if os.path.exists(
            os.path.join(preprocessed_dir, pdb_id_struct, chain_id + ".npz")
        ):
            continue

        print(pdb_id_struct, chain_id)
        # Reindex the chain and write to tmp.pdb
        dest = os.path.join(pre, "tmp.pdb")
        PDBtxt_reindex = reindex_pdb(
            os.path.join(pre, chain_id + ".fasta"),
            os.path.join(pre, "downloaded.pdb"),
            True,
        )
        # set_trace()
        if PDBtxt_reindex is None:
            print(pdb_id_struct, chain_id, "reindex fail")
            continue

        with open(dest, "w") as fp:
            fp.write(PDBtxt_reindex)

        # Initialize information required for the complex
        protein = initialize_protein_info(pdb_id_struct, chain_id)
        ligand = initialize_ligand_info(pdb_id_struct)

        # Make the dictionary for storage
        try:
            data = {}
            data["pdb_id_struct"] = pdb_id_struct
            data["chain_id"] = chain_id
            data["sequence"] = protein["sequence"]
            data["length"] = len(data["sequence"])
            data["labels"] = find_residues_in_contact(protein, ligand)
            # For structure-based prediction
            data["ca_dist_map_true"] = get_distance_map_true(protein, "CA")
            data["cb_dist_map_true"] = get_distance_map_true(protein, "CB")
            # For penalising the loss function better
            data["prot_lig_dist"] = get_protein_ligand_dist(protein, ligand)
            assert len(data["sequence"]) == len(data["labels"])
        except:
            print(pdb_id_struct, chain_id, "dictionary fail")
            continue

        # Remove the tmp.pdb file
        os.remove(dest)
        process_time += time() - process_time_start

        # Write the data to a numpy .npz file
        write_time_start = time()
        folder = os.path.join(preprocessed_dir, pdb_id_struct)
        if not os.path.exists(folder):
            os.mkdir(folder)
        np.savez(os.path.join(folder, chain_id + ".npz"), **data)
        write_time += time() - write_time_start

print("Processing time:", process_time)
print("Write time:", write_time)


# %%
# Let us take all the amino acid properties available from the AAindex database
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2238890/
# The file AA_properties in the data folder contains all the values
# We will take only the features which are the least correlated as our features
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from matplotlib import cm as cm

get_ipython().run_line_magic("matplotlib", "inline")

tmp_df = pd.read_csv("../data/AA_properties.csv", sep=",")
df = tmp_df.iloc[:, 7:].T


# Function used to normalize the values between 0 and 1
def normalize(df):
    result = df.copy()
    for feature_name in df.columns:
        max_value = df[feature_name].max()
        min_value = df[feature_name].min()
        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
    return result


# A way to view the correlation matrix
def correlation_matrix(df):
    fig = plt.figure()
    ax1 = fig.add_subplot(111)
    cmap = cm.get_cmap("jet", 30)
    cax = ax1.imshow(df.corr(), interpolation="nearest", cmap=cmap)
    ax1.grid(True)
    plt.title("Feature Correlation")
    labels = np.arange(0, len(df), 1)
    ax1.set_xticklabels(labels, fontsize=6)
    ax1.set_yticklabels(labels, fontsize=6)
    # Add colorbar, make sure to specify tick locations to match desired ticklabels
    fig.colorbar(cax, ticks=np.arange(-1.1, 1.1, 0.1))
    plt.show()


# Using spearman correlation
corr = df.corr("spearman")
threshold = 0.6
columns = np.full((corr.shape[0],), True, dtype=bool)
for i in range(corr.shape[0]):
    for j in range(i + 1, corr.shape[0]):
        if corr.iloc[i, j] >= threshold or corr.iloc[i, j] <= -threshold:
            if columns[j]:
                columns[j] = False
selected_columns = df.columns[columns]
features = df[selected_columns]

# Saving all the features and the selected features
normalize(df).to_csv("../data/all_features.csv")
normalize(features).to_csv("../data/selected_features.csv")


# %%
# Assuming that all the PSSMs have been copied to data/scPDB/pssm
# We can have more features included as well. For now, let us consider PSSMs
# !rsync -avP --include="*/" --include="*pssm" --exclude="*" ~/Git/msa-generator/data/scPDB/ ~/Git/protein-binding-site-prediction/data/scPDB/pssm/

# Get amino acid properties from the created files above
import csv
from collections import defaultdict

import numpy as np


def get_amino_acid_properties(csv_file):
    feats = {}
    with open(csv_file) as f:
        records = csv.reader(f)
        for i, row in enumerate(records):
            if i == 0:
                length = len(row) - 1
                continue
            feats[row[0]] = np.array(
                [float(el) if el != "" else 0.0 for el in row[1:]], dtype=np.float32
            )
        feats["X"] = np.zeros(length)
    feats = defaultdict(lambda: np.zeros(length), feats)
    return feats


# List of amino acids and their integer representation
AA_ID_DICT = {
    "X": 0,
    "A": 1,
    "C": 2,
    "D": 3,
    "E": 4,
    "F": 5,
    "G": 6,
    "H": 7,
    "I": 8,
    "K": 9,
    "L": 10,
    "M": 11,
    "N": 12,
    "P": 13,
    "Q": 14,
    "R": 15,
    "S": 16,
    "T": 17,
    "V": 18,
    "W": 19,
    "Y": 20,
}
AA_ID_DICT = defaultdict(lambda: 0, AA_ID_DICT)

# One-hot encoding and positional encoding
feat_vec_len = 21
feat_vec_len += 1

# We generated PSSMs for select sequences
# Mapping different sequences to the one for which we generated
common_pssms = defaultdict(str)
with open(os.path.join(data_dir, "unique"), "r") as f:
    for line in f.readlines():
        line = line.strip().split()
        pssm_generated_for = line[0][:-1]
        common_pssms[pssm_generated_for] = pssm_generated_for
        for pdb_id_struct_chain in line[1:]:
            pdb_id_struct_chain = pdb_id_struct_chain[:-1]
            common_pssms[pdb_id_struct_chain] = pssm_generated_for


def get_pssm(pdb_id_struct, chain_id, length):
    pssm_pdb_id_struct, pssm_chain_id = common_pssms[
        pdb_id_struct + "/" + chain_id
    ].split("/")
    with open(
        os.path.join(pssm_dir, pssm_pdb_id_struct, pssm_chain_id + ".pssm"), "r"
    ) as f:
        lines = f.readlines()
    feature = np.zeros((21, length))
    for i, line in enumerate(lines):
        feature[i] = np.array(line.strip().split(), dtype=np.float32)
    return feature


# PSSM length
feat_vec_len += 21

# Amino acid physico-chemical features selected by removing highly correlated features
AA_sel_feats = get_amino_acid_properties(
    os.path.join(os.path.dirname(data_dir), "selected_features.csv")
)
feat_vec_len += len(AA_sel_feats["X"])


# %%
# Now, let us preprocess the files again to generate the features
# directly that can be imported into pytorch easily
# For that we can define the 2 cells below where the generate_input function
# can be used to generate various types of inputss


# %%
# Without using distance map


def generate_input(sample):
    """
    Generate input for a single sample
    """
    X = np.zeros((feat_vec_len, sample["length"]))

    # One-hot encoding
    X[:21] = np.array([np.eye(21)[AA_ID_DICT[el]] for el in sample["sequence"]]).T

    # Positional encoding
    X[21] = np.arange(1, sample["length"] + 1, dtype=np.float32) / sample["length"]

    # PSSM
    X[22:43] = sample["pssm"]

    # AA Properties
    X[43:] = np.array([AA_sel_feats[aa] for aa in sample["sequence"]]).T

    return X


# Using the distance map to pick the closes 20 residues and creating features for each amino acid
# independent of the total protein structure
# Let us not use one-hot and positional encoding to save space and include distance?
# Amino acid no. + Distance from curr. aa + PSSM + AA Properties

# feat_vec_len = 1 + 1 + 21 + len(AA_sel_feats["X"])
# close_aa = 10
# import numpy as np


# def generate_input(sample):
#     X = np.zeros((feat_vec_len * close_aa, sample["length"]))
#     for i, aa_dist in enumerate(sample["ca_dist_map_true"]):
#         if sample["length"] <= close_aa:
#             indices = np.argsort(aa_dist)
#         else:
#             # Selects the smallest `close_aa` elements not in sorted order
#             indices = list(np.argpartition(aa_dist, close_aa)[:close_aa])
#             # Sort the indices according to their value
#             indices.sort(key=lambda x: aa_dist[x])
#         for j, idx in enumerate(indices):
#             if aa_dist[idx] == 1e6:
#                 # Implies we don't have structural info about any AA after this
#                 break
#             aa = sample["sequence"][idx]
#             X[j * feat_vec_len, i] = AA_ID_DICT[aa] / 20
#             X[j * feat_vec_len + 1, i] = aa_dist[idx]
#             X[j * feat_vec_len + 2 : j * feat_vec_len + 2 + 21, i] = sample["pssm"][:, idx]
#             X[j * feat_vec_len + 2 + 21 : (j + 1) * feat_vec_len, i] = np.array(AA_sel_feats[aa])
#     return X


# With an inverted distance map
# This does not work very well

# def generate_input(sample):
#     X = np.zeros((feat_vec_len, sample["length"]))

#     # One-hot encoding
#     X[:21] = np.array([np.eye(21)[AA_ID_DICT[el]] for el in sample["sequence"]]).T

#     # PSSM
#     X[22:43] = sample["pssm"]

#     # AA Properties
#     X[43:] = np.array([AA_sel_feats[aa] for aa in sample["sequence"]]).T

#     # Invert the distance map and matrix multiply with X so that we get a combination of all features
#     inverted_dist = 1 / sample["ca_dist_map_true"]
#     np.fill_diagonal(inverted_dist, 1.0)
#     X_T = inverted_dist.dot(X.T)
#     for i in range(sample["length"]):
#         X_T[i] = X_T[i] / np.sum(inverted_dist[i])

#     X = X_T.T

#     # Positional encoding
#     X[21] = np.arange(1, sample["length"] + 1, dtype=np.float32) / sample["length"]

#     return X


# %%
# USING CONCATENATION STRATEGY

# for pdb_id_struct in sorted(os.listdir(preprocessed_dir)):
#     flg = True
#     pre = os.path.join(preprocessed_dir, pdb_id_struct)
#     features_file = os.path.join(pre, "features.npy")
#     labels_file = os.path.join(pre, "labels.npy")

#     if os.path.exists(labels_file):
#         continue
#     print(pdb_id_struct)

#     for file in sorted(os.listdir(pre)):
#         # In case features were generated but not labels, redo it
#         if file == "features.npy":
#             continue
#         chain_id = file[-len(".npz") - 1 : -len(".npz")]
#         sample = np.load(os.path.join(pre, file))
#         sample = {
#             key: sample[key].item() if sample[key].shape is () else sample[key]
#             for key in sample
#         }
#         sample["pssm"] = get_pssm(pdb_id_struct, chain_id, sample["length"])
#         if flg:
#             X = generate_input(sample)
#             y = sample["labels"]
#             flg = False
#         else:
#             # Using concatenation strategy
#             tmp = generate_input(sample)
#             X = np.concatenate((X, tmp), 1)
#             y = np.concatenate((y, sample["labels"]), 0)

#     np.save(features_file, X)
#     np.save(labels_file, y)


# SAVING ALL CHAINS AS DIFFERENT PROTEINS
for pdb_id_struct in sorted(os.listdir(preprocessed_dir)):
    pre = os.path.join(preprocessed_dir, pdb_id_struct)
    print(pdb_id_struct)

    for file in sorted(os.listdir(pre)):
        # In case features were generated but not labels, redo it
        if not file.endswith(".npz"):
            continue
        chain_id = file[-len(".npz") - 1 : -len(".npz")]
        features_file = os.path.join(pre, "features" + chain_id + ".npy")
        labels_file = os.path.join(pre, "labels" + chain_id + ".npy")
        if os.path.exists(features_file) and os.path.exists(labels_file):
            continue
        sample = np.load(os.path.join(pre, file))
        sample = {
            key: sample[key].item() if sample[key].shape is () else sample[key]
            for key in sample
        }
        sample["pssm"] = get_pssm(pdb_id_struct, chain_id, sample["length"])
        X = generate_input(sample)
        y = sample["labels"]

        np.save(features_file, X)
        np.save(labels_file, y)


# %%
# Let us save the above files and store in a safe space
# DON'T USE


def archive_dir(folder, pattern, name):
    parent_dir = os.path.dirname(folder)
    folder = os.path.basename(folder)
    #     print(parent_dir, folder)
    if os.path.exists(os.path.join(parent_dir, name)):
        print("Warning:", name, "already exists in", parent_dir)
        inp = input("Do you want to overwrite existing file? (y/n): ")
        if inp[0].lower() == "n":
            return
    # Using only a single ! command since multiple ! spawn different bash shells


# For some reason, the below code is doubling the contents of the tar file
#     !cd $parent_dir; find $folder -name "$pattern" | tar --sort=name -I zstd -cf $name -T -; rsync -avP $name crvineeth97@ada:/share2/crvineeth97/compressed/scPDB; cd -
# To untar, use
# !tar -I zstd -xf $name


# archive_dir(raw_dir, "*", "raw.tar.zst")
# archive_dir(preprocessed_dir, "*.npy", "features_labels.tar.zst")
# archive_dir(preprocessed_dir, "*.npz", "preprocessed_chains.tar.zst")
# archive_dir(pssm_dir, "*", "pssm.tar.zst")
