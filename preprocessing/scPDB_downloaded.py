# %%
# Some constants that will be required
# ALWAYS RUN THIS CODE CELL
import os

data_dir = os.path.abspath("../data/scPDB")
raw_dir = os.path.join(data_dir, "raw")
pssm_dir = os.path.join(data_dir, "pssm")
splits_dir = os.path.join(data_dir, "splits")
preprocessed_dir = os.path.join(data_dir, "preprocessed")


# %%
# Download the scPDB dataset and extract the dataset in "data/scPDB/raw"
# resource = "http://bioinfo-pharma.u-strasbg.fr/scPDB/ressources/2016/scPDB.tar.gz"
# !aria2c -c -x 8 -s 8 -d $data_dir $resource --out 'scPDB.tar.gz'
# !tar xvzf ../data/scPDB/scPDB.tar.gz -C ../data/scPDB/raw/


# %%
# For 10-fold Cross Validation, we will use the splits that were generated by https://arxiv.org/abs/1904.06517
# resource = "https://gitlab.com/cheminfIBB/kalasanty/-/archive/master/kalasanty-master.tar.gz?path=data"
# !aria2c -c -x 8 -s 8 -d "../data/scPDB" $resource --out 'kalasanty-master-data.tar.gz'
# !tar xvzf ../data/scPDB/kalasanty-master-data.tar.gz -C ../data/scPDB/


# %%
# For sequence-based prediction, we need to use RCSB FASTA files and since scPDB has only mol2 files for proteins
# we will download the fasta file and PDB files of the given proteins. This allows for proper calculation of labels
# Note that the downloaded PDB automatically has all the structures of a particular PDB ID
# Hence, we just use the first structure instead of all
# Download sequence and PDB files from RCSB for easier matching of labels
import urllib

for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pdb_id = pdb_id_struct[:4]
    print(pdb_id)

    pdb_save = os.path.join(raw_dir, pdb_id_struct, "downloaded.pdb")
    if not os.path.exists(pdb_save):
        try:
            urllib.request.urlretrieve(
                "http://files.rcsb.org/download/" + pdb_id + ".pdb", pdb_save
            )
        except:  # noqa: E722
            print("Err: pdb " + pdb_id)

    fasta_save = os.path.join(raw_dir, pdb_id_struct, "sequence.fasta")
    if not os.path.exists(fasta_save):
        try:
            urllib.request.urlretrieve(
                "https://www.rcsb.org/pdb/download/downloadFastaFiles.do?structureIdList="
                + pdb_id
                + "&compressionType=uncompressed",
                fasta_save,
            )
        except:  # noqa: E722
            print("Err: fasta " + pdb_id)


# %%
# Check whether downloaded PDB and sequence files are correct
# A few of the PDB files have been obseleted and hence will have to manually download them
# I wrote down the manual mapping of the pdb id's but seem to have lost it
# But they can easily be found out from data/obseleted.txt file
import subprocess


def last_line(f):
    proc = subprocess.Popen(["tail", "-n", "1", f], stdout=subprocess.PIPE)
    line = proc.stdout.readlines()[0].decode("utf-8").strip()
    return line


for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pdb_id = pdb_id_struct[:4]
    pdb_save = os.path.join(raw_dir, pdb_id_struct, "downloaded.pdb")
    if last_line(pdb_save) != "END":
        print("Err: PDB " + pdb_id_struct)
    fasta_save = os.path.join(raw_dir, pdb_id_struct, "sequence.fasta")
    with open(fasta_save, "r") as f:
        line = f.readline()
        if line[0] != ">":
            print("Err: FASTA " + pdb_id_struct)


# %%
# We need to generate MSAs for the protein sequences in the dataset
# For that, we need to split the sequence.fasta file into respective chain.fasta files
# Also, we need to remove the fasta files of DNA/RNA seqeuences

for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, pdb_id_struct)
    # Read SEQRES entries in PDB file to determine whether a chain
    # has a protein sequence or not
    pdb_file = os.path.join(pre, "downloaded.pdb")
    do_not_include = set()
    with open(pdb_file, "r") as f:
        line = f.readline()
        while line[:6] != "SEQRES":
            line = f.readline()
        while line[:6] == "SEQRES":
            chain_id = line[11]
            residue = line[19:22]
            # Generally DNA/RNA have 1 or 2-letter codes
            if " " in residue:
                do_not_include.add(chain_id)
            line = f.readline()

    fasta = os.path.join(pre, "sequence.fasta")
    with open(fasta, "r") as f:
        header = f.readline()
        while 1:
            chain_id = header[6:7]
            sequence = ""
            line = f.readline()
            while line != "" and line is not None and line[0] != ">":
                sequence += line.strip()
                line = f.readline()
            if chain_id not in do_not_include:
                with open(os.path.join(pre, chain_id + ".fasta"), "w") as hlp:
                    hlp.write(header)
                    hlp.write(sequence + "\n")
            if line == "" or line is None:
                break
            header = line


# %%
# In case you want to delete the generated fasta files from the above cell, use this
# ! find $raw_dir -name "?.fasta" -delete


# %%
# Let us remove some other troublesome fasta files
# trouble = ["1m1d_1/D.fasta", # The PDB file does not contain structure of this sequence at all
#             "2xbm_4/E.fasta", # RNA sequence that slipped past somehow
#             "2xbm_4/F.fasta"] # RNA sequence that slipped past somehow
# for chain in trouble:
#     file = os.path.join(raw_dir, chain)
#     if os.path.exists(file):
#         os.remove(file)


# %%
# The fasta files generated will have a lot of common sequences
# To speed up MSA generation, let us create a unique file that has common sequences
# Then we can generate the MSAs for only the first chain in every line
from collections import defaultdict

sequences = defaultdict(list)
for file in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, file.strip())
    for fasta in sorted(os.listdir(pre)):
        if fasta[2:] != "fasta":
            continue
        chain_id = fasta[0]
        with open(os.path.join(pre, fasta)) as f:
            f.readline()
            sequence = f.readline().strip()
            # This choice was made so that rsync would work much better and easier
            sequences[sequence].append(file + "/" + chain_id + "*")

keys = list(sequences.keys())

with open(os.path.join(data_dir, "unique"), "w") as f:
    for key in keys:
        line = ""
        for chain_id in sequences[key]:
            line += chain_id + " "
        f.write(line[:-1] + "\n")


# %%
# Run a regex search on the generated fasta files to ensure that we don't have any DNA/RNA sequences
# Will have to manually check the files to ensure that they are protein sequences
# All of them are protein sequences
import re


def match(strg, search=re.compile(r"[^ACGTURYKMSWBDHVN\-\.]").search):
    return not bool(search(strg))


with open(os.path.join(data_dir, "unique"), "r") as f:
    lines = f.readlines()

for line in lines:
    pdb_id_struct, chain_id = line.strip().split()[0].split("/")
    chain_id = chain_id[0]
    with open(os.path.join(raw_dir, pdb_id_struct, chain_id + ".fasta"), "r") as f:
        f.readline()
        seq = f.readline().strip()
    if match(seq):
        print(pdb_id_struct, chain_id)


# %%
# MSAs need to be generated for the fasta files
# Refer to https://github.com/crvineeth97/msa-generator


# %%
# MAKING OF .npz FILES FROM HERE
# Download NWalign.py, pdb2fasta.py and reindex_pdb.py
# https://zhanglab.ccmb.med.umich.edu/NW-align/NWalign.py (Make small changes for Python3 compatibility)
# https://zhanglab.ccmb.med.umich.edu/reindex_pdb/reindex_pdb.py (Make changes to allow for reindexing specific chains
# and also to replace celenocysteine, "U" with "X")
# https://zhanglab.ccmb.med.umich.edu/reindex_pdb/pdb2fasta.py (Almost the same)
# Let us preprocess ALL available data and create .npz files
# The following will fail reindexing
# 1m1d_1 D, 2xbm_4 E, 2xbm_4 F, 3h9j_6 E, 3h9j_6 F, 3h9j_6 H, 4mfp_1 B, 4mfq_1 B,
# 4oav_2 A, 4oav_2 C, 7kme_1 J because they are not protein chains
import warnings
from time import time

import numpy as np

from Bio import BiopythonWarning
from Bio.PDB import PDBParser, is_aa
from rdkit import Chem
from rdkit.Chem.rdMolTransforms import ComputeCentroid
from preprocessing.utils.reindex_pdb import reindex_pdb

warnings.simplefilter("ignore", BiopythonWarning)
parser = PDBParser()


def initialize_protein_info(pdb_id_struct, chain_id):
    """
    pdb_id_struct: 10mh_1 from scPDB
    chain_id: The chain that is being parsed

    Returns: protein = {"structure": ..., "chainA": {"residues": ..., "seqeunce": ...}, ...}
    """
    pre = os.path.join(raw_dir, pdb_id_struct)
    protein = {}
    protein["structure"] = parser.get_structure(
        pdb_id_struct, os.path.join(pre, "reindexed_" + chain_id + ".pdb")
    )

    protein["residues"] = []
    for res in protein["structure"][0][chain_id]:
        id = res.get_id()
        if is_aa(res, standard=False) and id[0] == " ":
            protein["residues"].append(res)

    protein["sequence"] = ""
    with open(os.path.join(pre, chain_id + ".fasta")) as f:
        line = f.readline()
        line = f.readline()
        while line != "" and line is not None:
            protein["sequence"] += line.strip()
            line = f.readline()
    return protein


def initialize_ligand_info(pdb_id_struct):
    """
    pdb_id_struct: 10mh_1 from scPDB

    Returns: ligand = {"supplier": ..., "coords": ..., "num_atoms": ..., "atom_types": ...}
    """
    pre = os.path.join(raw_dir, pdb_id_struct)
    ligand = {}
    ligand["supplier"] = Chem.SDMolSupplier(
        os.path.join(pre, "ligand.sdf"), sanitize=False
    )
    assert len(ligand["supplier"]) == 1
    ligand["supplier"] = ligand["supplier"][0]
    assert ligand["supplier"].GetNumConformers() == 1
    ligand["coords"] = ligand["supplier"].GetConformer().GetPositions()
    ligand["num_atoms"] = ligand["supplier"].GetNumAtoms()
    assert ligand["num_atoms"] == len(ligand["coords"])
    ligand["atom_types"] = np.array(
        [atom.GetSymbol() for atom in ligand["supplier"].GetAtoms()]
    )
    return ligand


def find_residues_in_contact(protein, ligand, cutoff=5.0):
    """
    Returns a numpy 1D array where a 1 represents that the amino acid is in
    contact with the ligand
    """
    labels = np.zeros(len(protein["sequence"]))
    for residue in protein["residues"]:
        res_ind = residue.get_id()[1] - 1
        for atom in residue.get_atoms():
            if atom.get_fullname()[1] == "H":
                continue
            for i in range(ligand["num_atoms"]):
                if ligand["atom_types"][i] == "H":
                    continue
                # We are considering the ligand to be in contact with the AA
                # if the distance between them is within cutoff Angstroms
                if np.linalg.norm(atom.get_coord() - ligand["coords"][i]) <= cutoff:
                    labels[res_ind] = 1
                    break
            # We know that the residue is in contact with ligand
            # So go to the next residue
            if labels[res_ind]:
                break
    return labels


def get_protein_ligand_dist(protein, ligand):
    """
    protein: protein[chain] dictionary from initialize_protein_info
    ligand: ligand dictionary from initialize_ligand_info

    Returns: A numpy 1D array of shape (L,) where L is length of RCSB sequence
            and the real numbers represent the distance of the ligand centroid
            from the CB (CA) atom of the amino acid (Gly)
    """
    centroid = ComputeCentroid(ligand["supplier"].GetConformer())
    centroid = np.array([centroid.x, centroid.y, centroid.z])
    dist = np.full(len(protein["sequence"]), 1e6)
    for residue in protein["residues"]:
        res_ind = residue.get_id()[1] - 1
        if residue.has_id("CB"):
            atom_type = "CB"
        elif residue.has_id("CA"):
            atom_type = "CA"
        else:
            continue
        dist[res_ind] = np.linalg.norm(residue[atom_type].get_coord() - centroid)
    return dist


def get_distance_map_true(protein):
    """
    protein: protein[chain] dictionary from initialize_protein_info

    Returns: A 2D numpy array of shape (L, L) where L is the length of the RCSB sequence
            and the real numbers of row i and column j represents the distance between
            the CB (CA) of i'th amino acid (Gly) and CB (CA) of j'th amino acid (Gly)
    """
    seq_len = len(protein["sequence"])
    # Might be different from seq_len because of missing residues
    num_residues = len(protein["residues"])
    # Don't use np.inf, use an impossibly large number
    distance_map = np.full((seq_len, seq_len), 1e6)  # Initialize to infinite distance
    for ind1 in range(num_residues):
        at1 = "CB"
        res1 = protein["residues"][ind1]
        if not res1.has_id("CB"):
            at1 = "CA"
            if not res1.has_id("CA"):
                continue
        res1_ind = res1.get_id()[1] - 1
        for ind2 in range(ind1 + 1, num_residues):
            at2 = "CB"
            res2 = protein["residues"][ind2]
            if not res2.has_id("CB"):
                at2 = "CA"
                if not res2.has_id("CA"):
                    continue
            res2_ind = res2.get_id()[1] - 1
            dist = np.linalg.norm(res1[at1].get_coord() - res2[at2].get_coord())
            distance_map[res1_ind][res2_ind] = dist
            distance_map[res2_ind][res1_ind] = dist
    # Fill the diagonal with 0's
    np.fill_diagonal(distance_map, 0.0)
    return distance_map


if not os.path.exists(preprocessed_dir):
    os.mkdir(preprocessed_dir)

process_time = 0
write_time = 0
for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, pdb_id_struct)
    process_time_start = time()
    for file in sorted(os.listdir(pre)):
        # Get only the chain fasta sequences
        if file[2:] != "fasta":
            continue
        chain_id = file[0]

        # If our preprocessed file exists, continue
        if os.path.exists(
            os.path.join(preprocessed_dir, pdb_id_struct, chain_id + ".npz")
        ):
            continue

        print(pdb_id_struct, chain_id)
        # Reindex the chain and write to file
        dest = os.path.join(pre, "reindexed_" + chain_id + ".pdb")
        PDBtxt_reindex = reindex_pdb(
            os.path.join(pre, chain_id + ".fasta"),
            os.path.join(pre, "downloaded.pdb"),
            True,
        )

        if PDBtxt_reindex is None:
            print(pdb_id_struct, chain_id, "reindex fail")
            continue

        with open(dest, "w") as fp:
            fp.write(PDBtxt_reindex)

        # Initialize information required for the complex
        protein = initialize_protein_info(pdb_id_struct, chain_id)
        ligand = initialize_ligand_info(pdb_id_struct)

        # Make the dictionary for storage
        try:
            data = {}
            data["pdb_id_struct"] = pdb_id_struct
            data["chain_id"] = chain_id
            data["sequence"] = protein["sequence"]
            data["length"] = len(data["sequence"])
            data["labels"] = find_residues_in_contact(protein, ligand)
            # For structure-based prediction
            data["dist_map_true"] = get_distance_map_true(protein)
            # For penalising the loss function better
            data["prot_lig_dist"] = get_protein_ligand_dist(protein, ligand)
            assert len(data["sequence"]) == len(data["labels"])
        except:  # noqa: E722
            print(pdb_id_struct, chain_id, "dictionary fail")
            continue

        process_time += time() - process_time_start

        # Write the data to a numpy .npz file
        write_time_start = time()
        folder = os.path.join(preprocessed_dir, pdb_id_struct)
        if not os.path.exists(folder):
            os.mkdir(folder)
        np.savez(os.path.join(folder, chain_id + ".npz"), **data)
        write_time += time() - write_time_start

print("Processing time:", process_time)
print("Write time:", write_time)
