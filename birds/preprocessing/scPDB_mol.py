# %%
# Some constants that will be required
# ALWAYS RUN THIS CODE CELL
import os

data_dir = os.path.abspath("../data/2018_scPDB")
raw_dir = os.path.join(data_dir, "raw")
preprocessed_dir = os.path.join(data_dir, "preprocessed")


# %%
# Download the scPDB dataset and extract the dataset in "data/scPDB/raw"
# resource = "http://bioinfo-pharma.u-strasbg.fr/scPDB/ressources/2016/scPDB.tar.gz"
# !aria2c -c -x 8 -s 8 -d $data_dir $resource --out 'scPDB.tar.gz'
# !tar xvzf ../data/scPDB/scPDB.tar.gz -C ../data/scPDB/raw/


# %%
# For 10-fold Cross Validation, we will use the splits that were generated by https://arxiv.org/abs/1904.06517
# resource = "https://gitlab.com/cheminfIBB/kalasanty/-/archive/master/kalasanty-master.tar.gz?path=data"
# !aria2c -c -x 8 -s 8 -d "../data/scPDB" $resource --out 'kalasanty-master-data.tar.gz'
# !tar xvzf ../data/scPDB/kalasanty-master-data.tar.gz -C ../data/scPDB/


# %%
# For sequence-based prediction, we need to use RCSB FASTA files
# import urllib.request

# for pdb_id_struct in sorted(os.listdir(raw_dir)):
#     pdb_id = pdb_id_struct[:4]
#     # print(pdb_id)

#     fasta_save = os.path.join(raw_dir, pdb_id_struct, "sequence.fasta")
#     if not os.path.exists(fasta_save):
#         try:
#             urllib.request.urlretrieve(
#                 "https://www.rcsb.org/pdb/download/downloadFastaFiles.do?structureIdList="
#                 + pdb_id
#                 + "&compressionType=uncompressed",
#                 fasta_save,
#             )
#         except:  # noqa: E722
#             print("Err: fasta " + pdb_id)


# %%
# Check whether downloaded sequence files are correct
# A few of the PDB files have been obseleted and hence will have to manually download them
# I wrote down the manual mapping of the pdb id's but seem to have lost it
# But they can easily be found out from data/obseleted.txt file

for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pdb_id = pdb_id_struct[:4]
    fasta_save = os.path.join(raw_dir, pdb_id_struct, "sequence.fasta")
    with open(fasta_save, "r") as f:
        line = f.readline()
        if line[0] != ">":
            print("Err: FASTA " + pdb_id_struct)


# %%
# Let us reindex protein.mol2 and site.mol2 and convert to PDB format
# So that they can be imported using biopython
# Also let us write fasta sequence for the chains in protein.mol2 files
# Download NWalign.py to use Needlman Wunsch algorithm to align sequences
# https://zhanglab.ccmb.med.umich.edu/NW-align/NWalign.py (Make small changes for Python3 compatibility)
# 4egb_5 is an obseleted PDB and hence has chain E, had to manually add E to sequence.fasta
from birds.utilities.mol2 import Mol2
from tqdm.auto import tqdm

for pdb_id_struct in tqdm(sorted(os.listdir(raw_dir))):
    pre = os.path.join(raw_dir, pdb_id_struct)
    sequence_fasta = os.path.join(pre, "sequence.fasta")
    reindexed_prot = os.path.join(pre, "reindexed_protein.pdb")
    reindexed_site = os.path.join(pre, "reindexed_site.pdb")
    if os.path.exists(reindexed_site):
        continue
    # print(pdb_id_struct)
    # if pdb_id_struct == "1a5s_1":
    #     exit(1)

    # Import mol2 and reindex the protein according to sequence fasta
    try:
        prot_mol = Mol2(os.path.join(pre, "protein.mol2"))
        site_mol = Mol2(os.path.join(pre, "site.mol2"))
        prot_mol.reindex(sequence_fasta)
    except:
        print("Reindex Error", pdb_id_struct)
        continue

    # Reindex site.mol2 file according to the alignment from protein.mol2
    site_mol.subst_df["reindex_id"] = 0
    for i, record in enumerate(site_mol.subst_df[["subst_name", "chain"]].values):
        reindex_id = prot_mol.subst_df[
            (prot_mol.subst_df["subst_name"] == record[0])
            & (prot_mol.subst_df["chain"] == record[1])
        ]["reindex_id"]
        # Typically it should not be empty, but very minor error in dataset I think
        if not reindex_id.empty:
            site_mol.subst_df.at[i, "reindex_id"] = reindex_id

    # Write back the reindexed files as pdb
    prot_mol.write_pdb(reindexed_prot)
    site_mol.write_pdb(reindexed_site)

    # We need to generate MSA's, hence store only the fasta of chains
    # from the above protein
    with open(sequence_fasta, "r") as f:
        header = f.readline()
        while 1:
            chain_id = header[6:7]
            sequence = ""
            line = f.readline()
            while line != "" and line is not None and line[0] != ">":
                sequence += line.strip()
                line = f.readline()
            # No need to replace here because U and O will be considered X automatically while making features
            # sequence = sequence.replace("U", "X").replace("O", "X")
            if chain_id in prot_mol.sequences:
                with open(os.path.join(pre, chain_id + ".fasta"), "w") as hlp:
                    hlp.write(header)
                    hlp.write(sequence + "\n")
            if line == "" or line is None:
                break
            header = line


# %%
# In case you want to delete the generated fasta and reindexed files from the above cell, use this
# ! find ../data/scPDB/raw/ -name "?.fasta" -delete
# ! find ../data/scPDB/raw/ -name "reindexed_*" -delete


# %%
# The fasta files generated will have a lot of common sequences
# To speed up MSA generation, let us create a unique file that has common sequences
# Then we can generate the MSAs for only the first chain in every line
# from collections import defaultdict

# sequences = defaultdict(list)
# for file in sorted(os.listdir(raw_dir)):
#     pre = os.path.join(raw_dir, file.strip())
#     for fasta in sorted(os.listdir(pre)):
#         if fasta[2:] != "fasta":
#             continue
#         chain_id = fasta[0]
#         with open(os.path.join(pre, fasta)) as f:
#             f.readline()
#             sequence = f.readline().strip()
#             # This choice was made so that rsync would work much better and easier
#             sequences[sequence].append(file + "/" + chain_id + "*")

# keys = list(sequences.keys())

# with open(os.path.join(data_dir, "unique"), "w") as f:
#     for key in keys:
#         line = ""
#         for chain_id in sequences[key]:
#             line += chain_id + " "
#         f.write(line[:-1] + "\n")


# %%
# MSAs need to be generated for the fasta files
# Refer to https://github.com/crvineeth97/msa-generator


# %%
# MAKING OF .npz FILES FROM HERE
# Let us preprocess ALL the available data and create .npz files which contains the required information of each chain
import warnings

import numpy as np

from Bio import BiopythonWarning
from Bio.PDB import PDBParser, is_aa
from rdkit import Chem
from rdkit.Chem.rdMolTransforms import ComputeCentroid

warnings.simplefilter("ignore", BiopythonWarning)
parser = PDBParser()


def initialize_protein_info(pdb_id_struct, name):
    """
    pdb_id_struct: 10mh_1 from scPDB
    name: Whether reindexed_site.pdb or reindexed_protein.pdb

    Returns: protein = {"structure": ..., "chainA": {"residues": ..., "seqeunce": ...}, ...}
    """
    pre = os.path.join(raw_dir, pdb_id_struct)
    protein = {}
    protein["structure"] = parser.get_structure(pdb_id_struct, os.path.join(pre, name))

    for chain in protein["structure"][0]:
        chain_id = chain.get_id()
        protein[chain_id] = {}
        protein[chain_id]["residues"] = []
        for res in chain:
            id = res.get_id()
            # Include all types of residues, not only the standard 20
            if is_aa(res, standard=False) and id[0] == " ":
                protein[chain_id]["residues"].append(res)

        # Stores the RCSB sequence of the protein, not the sequence from protein
        protein[chain_id]["sequence"] = ""
        with open(os.path.join(pre, chain_id + ".fasta")) as f:
            line = f.readline()
            line = f.readline()
            while line != "" and line is not None:
                protein[chain_id]["sequence"] += line.strip()
                line = f.readline()
    return protein


def initialize_ligand_info(pdb_id_struct):
    """
    pdb_id_struct: 10mh_1 from scPDB

    Returns: ligand = {"supplier": ..., "coords": ..., "num_atoms": ..., "atom_types": ...}
    """
    pre = os.path.join(raw_dir, pdb_id_struct)
    ligand = {}
    ligand["supplier"] = Chem.SDMolSupplier(
        os.path.join(pre, "ligand.sdf"), sanitize=False
    )
    assert len(ligand["supplier"]) == 1
    ligand["supplier"] = ligand["supplier"][0]
    assert ligand["supplier"].GetNumConformers() == 1
    ligand["coords"] = ligand["supplier"].GetConformer().GetPositions()
    ligand["num_atoms"] = ligand["supplier"].GetNumAtoms()
    assert ligand["num_atoms"] == len(ligand["coords"])
    ligand["atom_types"] = np.array(
        [atom.GetSymbol() for atom in ligand["supplier"].GetAtoms()]
    )
    return ligand


def find_site_residues(protein, site):
    """
    protein: protein[chain] dictionary from initialize_protein_info
    site: site dictionary from initialize_protein_info

    Returns: A numpy 1D array of shape (L,) where L is length of RCSB sequence
    and 1 represents that the amino acid is in contact with the ligand
    """
    seq_len = len(protein["sequence"])
    labels = ["0"] * seq_len
    for residue in site["residues"]:
        res_ind = residue.get_id()[1] - 1
        if res_ind >= seq_len:
            # These are X markers mostly
            continue
        labels[res_ind] = "1"
    return "".join(labels)


def get_protein_ligand_dist(protein, ligand):
    """
    protein: protein[chain] dictionary from initialize_protein_info
    ligand: ligand dictionary from initialize_ligand_info

    Returns: A numpy 1D array of shape (L,) where L is length of RCSB sequence
            and the real numbers represent the distance of the ligand centroid
            from the CB (CA) atom of the amino acid (Gly)
    """
    # NOTE: DO NOT USE CENTROID. LEADING TO NANS
    centroid = ComputeCentroid(ligand["supplier"].GetConformer())
    centroid = np.array([centroid.x, centroid.y, centroid.z])
    seq_len = len(protein["sequence"])
    dist = np.full(seq_len, 1e6)
    for residue in protein["residues"]:
        res_ind = residue.get_id()[1] - 1
        if res_ind >= seq_len:
            continue
        if residue.has_id("CB"):
            atom_type = "CB"
        elif residue.has_id("CA"):
            atom_type = "CA"
        else:
            continue
        dist[res_ind] = np.linalg.norm(residue[atom_type].get_coord() - centroid)
    return dist


def get_distance_map_true(protein):
    """
    protein: protein[chain] dictionary from initialize_protein_info

    Returns: A 2D numpy array of shape (L, L) where L is the length of the RCSB sequence
            and the real numbers of row i and column j represents the distance between
            the CB (CA) of i'th amino acid (Gly) and CB (CA) of j'th amino acid (Gly)
    """
    seq_len = len(protein["sequence"])
    # Might be different from seq_len because of missing residues
    num_residues = len(protein["residues"])
    # Don't use np.inf, use an impossibly large number
    distance_map = np.full((seq_len, seq_len), 1e6)  # Initialize to infinite distance
    for ind1 in range(num_residues):
        at1 = "CB"
        res1 = protein["residues"][ind1]
        if not res1.has_id("CB"):
            at1 = "CA"
            if not res1.has_id("CA"):
                continue
        res1_ind = res1.get_id()[1] - 1
        # There might be some X at the end of the fasta and might have been written to reindexed pdb
        if res1_ind >= seq_len:
            print("Ignored residue", res1.get_resname())
            continue
        for ind2 in range(ind1 + 1, num_residues):
            at2 = "CB"
            res2 = protein["residues"][ind2]
            if not res2.has_id("CB"):
                at2 = "CA"
                if not res2.has_id("CA"):
                    continue
            res2_ind = res2.get_id()[1] - 1
            if res2_ind >= seq_len:
                continue
            dist = np.linalg.norm(res1[at1].get_coord() - res2[at2].get_coord())
            distance_map[res1_ind][res2_ind] = dist
            distance_map[res2_ind][res1_ind] = dist
    # Fill the diagonal with 0's
    np.fill_diagonal(distance_map, 0.0)
    return distance_map


# Run the preprocessing here
if not os.path.exists(preprocessed_dir):
    os.mkdir(preprocessed_dir)

# info_file = os.path.join(data_dir, "info.txt")
# if os.path.exists(info_file):
#     print("Warning: Save info.txt")
#     exit(1)

for pdb_id_struct in sorted(os.listdir(raw_dir)):
    pre = os.path.join(raw_dir, pdb_id_struct)
    chains = []
    # Check according the fasta files of chains which were generated
    for file in sorted(os.listdir(pre)):
        if file[2:] != "fasta":
            continue
        chain_id = file[0]
        if os.path.exists(
            os.path.join(preprocessed_dir, pdb_id_struct, chain_id + ".npz")
        ):
            continue
        chains.append(chain_id)

    # Means preprocessing of all chains has been done
    if chains == []:
        continue

    # Initialize information required for the complex
    protein = initialize_protein_info(pdb_id_struct, "reindexed_protein.pdb")
    site = initialize_protein_info(pdb_id_struct, "reindexed_site.pdb")
    ligand = initialize_ligand_info(pdb_id_struct)

    for chain_id in chains:
        print(pdb_id_struct, chain_id)
        # Generally should be the case but to avoid corner cases
        # if chain_id in site:
        #     labels = find_site_residues(protein[chain_id], site[chain_id])
        # else:
        #     print("Following not part of binding site", pdb_id_struct, chain_id)
        #     labels = "0" * len(protein[chain_id]["sequence"])
        # with open(info_file, "a") as f:
        #     f.write(
        #         "\t".join(
        #             [
        #                 pdb_id_struct[:4],
        #                 pdb_id_struct[5:],
        #                 chain_id,
        #                 protein[chain_id]["sequence"],
        #                 labels,
        #             ]
        #         )
        #         + "\n"
        #     )
        # Make the dictionary for storage
        try:
            data = {}
            # For structure-based prediction
            data["dist_map_true"] = get_distance_map_true(protein[chain_id]).astype(
                np.float32
            )
            # For penalising the loss function better
            data["prot_lig_dist"] = get_protein_ligand_dist(
                protein[chain_id], ligand
            ).astype(np.float32)
        except:  # noqa: E722
            print(pdb_id_struct, chain_id, "dictionary fail")
            continue

        if np.isnan(data["prot_lig_dist"]).any():
            print(pdb_id_struct, chain_id, "NAN")
            exit(1)
        # Write the data to a numpy .npz file
        folder = os.path.join(preprocessed_dir, pdb_id_struct)
        if not os.path.exists(folder):
            os.mkdir(folder)
        np.savez(os.path.join(folder, chain_id + ".npz"), **data)
