{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code is used for msa_generation\n",
    "# An scPDB.tar.gz file is already present in the repo and it contains sequence.fasta and downloaded.pdb files for all the scPDB data points\n",
    "# Let us extract that into data/scPDB\n",
    "# Most of the code is taken from Deepmsa https://zhanglab.ccmb.med.umich.edu/DeepMSA/ with some small changes\n",
    "!tar xvzf scPDB.tar.gz -C ../data/\n",
    "# Download uniref50.fasta and uniclust30_2017_10 into data folder\n",
    "!aria2c -c -x 8 -s 8 -d \"../data/\" ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz\n",
    "!aria2c -c -x 8 -s 8 -d \"../data/\" http://wwwuser.gwdg.de/~compbiol/uniclust/2017_10/uniclust30_2017_10_hhsuite.tar.gz\n",
    "!tar xvzf ./data/uniref50.fasta.gz -C ./data/\n",
    "!tar xvzf ./data/uniclust30_2017_10_hhsuite.tar.gz -C ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important constants\n",
    "# ENSURE THAT YOU RUN THIS CODE CELL FIRST\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "data_dir = os.path.abspath(\"../data\")\n",
    "dataset_dir = os.path.join(data_dir, \"scPDB\")\n",
    "raw_dir = os.path.join(dataset_dir, \"raw\")\n",
    "splits_dir = os.path.join(raw_dir, \"splits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to generate MSAs for the protein sequences in the dataset\n",
    "# For that, we need to split the sequence.fasta file into respective chain.fasta files\n",
    "# Also, we need to remove the fasta files of DNA/RNA seqeuences\n",
    "\n",
    "for file in sorted(os.listdir(raw_dir)):\n",
    "    file = file.strip()\n",
    "    pre = os.path.join(raw_dir, file)\n",
    "\n",
    "    # Read SEQRES entries in PDB file to determine whether a chain\n",
    "    # has a protein sequence or not\n",
    "    pdb_file = os.path.join(pre, \"downloaded.pdb\")\n",
    "    do_not_include = set()\n",
    "    with open(pdb_file, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        while line[:6] != \"SEQRES\":\n",
    "            line = f.readline()\n",
    "        while line[:6] == \"SEQRES\":\n",
    "            chain_id = line[11]\n",
    "            residue = line[19:22]\n",
    "            # Generally DNA/RNA have 1 or 2-letter codes\n",
    "            if \" \" in residue:\n",
    "                do_not_include.add(chain_id)\n",
    "            line = f.readline()\n",
    "\n",
    "    fasta = os.path.join(pre, \"sequence.fasta\")\n",
    "    create_chains_from_sequence_fasta(pre, fasta, do_not_include)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to delete the generated fasta files from the above cell, use this\n",
    "# for file in sorted(os.listdir(raw_dir)):\n",
    "#     for fasta in glob(os.path.join(raw_dir, file.strip(), \"?.fasta\")):\n",
    "#         os.remove(fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fasta files generated will have a lot of common sequences\n",
    "# To speed up MSA generation, let us create a unique file that has common sequences\n",
    "# Then we can generate the MSAs for only the first chain in every line\n",
    "make_unique_file(raw_dir, splits_dir)\n",
    "\n",
    "# Let us split the MSAs into a 100 files so that they can all be run parallely\n",
    "split_unique_file(splits_dir, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that boost regex library has been installed\n",
    "# MSAs take a lot of time to generate. Assuming a SLURM Workload Manager on the cluster, slurm.sh and generate_msa.py have been written. Make changes accordingly to make it work\n",
    "# Run slurm.sh\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "962b6f1acb3b863e31b2fe9e6f4fe7c71e05870b1f0e5c1f93ae83ed40347810"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pyt': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}