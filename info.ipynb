{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b356f74b944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPDB\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnglview\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mREFINED_FOLDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/PDBbind/pdbbind_v2018_refined/refined-set/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import *\n",
    "from rdkit import Chem\n",
    "\n",
    "# import nglview as nv\n",
    "import numpy as np\n",
    "\n",
    "REFINED_FOLDER = \"./data/PDBbind/pdbbind_v2018_refined/refined-set/\"\n",
    "INDEX_FOLDER = \"./data/PDBbind/PDBbind_2018_plain_text_index/index/\"\n",
    "parser = PDBParser()\n",
    "ppb = PPBuilder()\n",
    "# pdb_id = \"3aqt\"\n",
    "pdb_id = \"1ezq\"\n",
    "\n",
    "# Protein structure\n",
    "structure = parser.get_structure(\n",
    "    pdb_id, REFINED_FOLDER + pdb_id + \"/\" + pdb_id + \"_protein.pdb\"\n",
    ")\n",
    "\n",
    "# Ligand structure\n",
    "suppl = Chem.SDMolSupplier(\n",
    "    REFINED_FOLDER + pdb_id + \"/\" + pdb_id + \"_ligand.sdf\", sanitize=False\n",
    ")\n",
    "assert len(suppl) == 1\n",
    "assert suppl[0].GetNumConformers() == 1\n",
    "\n",
    "ligand_coords = suppl[0].GetConformer().GetPositions()\n",
    "ligand_num_atoms = suppl[0].GetNumAtoms()\n",
    "assert ligand_num_atoms == len(ligand_coords)\n",
    "ligand_atom_types = np.array([atom.GetSymbol() for atom in suppl[0].GetAtoms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distance cut-off for a protein ligand interaction\n",
    "residues = [residue for residue in structure.get_residues() if is_aa(residue)]\n",
    "\n",
    "labels = np.zeros(len(residues))\n",
    "\n",
    "for ind, residue in enumerate(residues):\n",
    "    for atom in residue.get_atoms():\n",
    "        if atom.get_fullname()[1] == 'H':\n",
    "            continue\n",
    "        for i in range(ligand_num_atoms):\n",
    "            if ligand_atom_types[i] == 'H':\n",
    "                continue\n",
    "            if np.linalg.norm(atom.get_coord() - ligand_coords[i]) < 4.5:\n",
    "                labels[ind] = 1\n",
    "                # print(residue.get_resname(), residue.get_segid())\n",
    "                break\n",
    "        if labels[ind]:\n",
    "            break\n",
    "\n",
    "# Manually check in VMD whether these amino acids are the ones close to the ligand\n",
    "print((np.where(labels == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique proteins in our dataset\n",
    "\n",
    "with open(INDEX_FOLDER + \"INDEX_refined_name.2018\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# lengths=[]\n",
    "dic = {}\n",
    "for line in lines:\n",
    "    if line[0] == \"#\":\n",
    "        continue\n",
    "    line = line.strip().split()\n",
    "    uniprot = line[3]\n",
    "    dic[uniprot] = 1\n",
    "\n",
    "print(len(dic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all proteins with same sequence and create another dataset with the labels of these sequences combined\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from constants import TRAIN_FOLDER, TEST_FOLDER, VAL_FOLDER\n",
    "from collections import defaultdict\n",
    "\n",
    "folders = [TRAIN_FOLDER, TEST_FOLDER, VAL_FOLDER]\n",
    "dic = {}\n",
    "unique = [set(), set(), set()]\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    for file in listdir(folder):\n",
    "        data = np.load(folder + file, allow_pickle=True)\n",
    "        protein = data[\"protein\"].item()\n",
    "        metadata = data[\"metadata\"].item()\n",
    "        seq = protein[\"sequence\"]\n",
    "        unique[i].add(seq)\n",
    "        if seq in dic:\n",
    "            for key in metadata:\n",
    "                dic[seq][\"metadata\"][key].append(metadata[key])\n",
    "            dic[seq][\"protein\"][\"labels\"] += protein[\"labels\"]\n",
    "        else:\n",
    "            dic[seq] = {}\n",
    "            dic[seq][\"metadata\"] = {}\n",
    "            for key in metadata:\n",
    "                dic[seq][\"metadata\"][key] = [metadata[key]]\n",
    "            dic[seq][\"protein\"] = protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've added all the labels together so if a binding site occurs in more than half the ligands, then we assume it is the important site and consider it as our label\n",
    "for i, key in enumerate(dic):\n",
    "    ln = len(dic[key][\"metadata\"][\"pdb_id\"]) // 2\n",
    "    dic[key][\"protein\"][\"labels\"] = (dic[key][\"protein\"][\"labels\"] > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "383\n",
      "381\n",
      "237\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "# Some statistics on the common sequences in test train and val data\n",
    "print(len(s[0]))\n",
    "print(len(s[1]))\n",
    "print(len(s[2]))\n",
    "print(len(s[1]-s[0]))\n",
    "print(len(s[2]-s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'pdb_id': ['2j94', '2uwl', '1nfu', '2vh0'], 'resolution': [2.1, 1.9, 2.05, 1.7], 'release_year': [2007, 2007, 2003, 2008], 'neg_log_k': [6.27, 8.4, 7.74, 8.51], 'k': [5.34e-07, 4e-09, 1.8000000000000002e-08, 3.1000000000000005e-09], 'ligand_name': ['G15', '895', 'RRP', 'GSI']}, 'protein': {'sequence': 'IVGGQECKDGECPWQALLINEENEGFCGGTILSEFYILTAAHCLYQAKRFKVRVGDRNTEQEEGGEAVHEVEVVIKHNRFTKETYDFDIAVLRLKTPITFRMNVAPACLPERDWAESTLMTQKTGIVSGFGRTHEKGRQSTRLKMLEVPYVDRNSCKLSSSFIITQNMFCAGYDTKQEDACQGDSGGPHVTRFKDTYFVTGIVSWGEGCARKGKYGIYTKVTAFLKWIDRSMKTRKLCSLDNGDCDQFCHEEQNSVVCSCARGYTLADNGKACIPTGPYPCGKQTL', 'length': 286, 'labels': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}}\n"
     ]
    }
   ],
   "source": [
    "# Check whether the dictionary made is correct or not\n",
    "for key in dic:\n",
    "    if len(dic[key][\"metadata\"][\"pdb_id\"]) > 1:\n",
    "        print(dic[key])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "for key in dic:\n",
    "    ln = len(dic[key][\"metadata\"][\"pdb_id\"])\n",
    "    pdb_id = dic[key][\"metadata\"][\"pdb_id\"][0] + \"-\" + str(ln)\n",
    "    np.savez(\n",
    "        \"./data/PDBbind/preprocessed/unique2/\" + pdb_id + \".npz\",\n",
    "        metadata=dic[key][\"metadata\"],\n",
    "        protein=dic[key][\"protein\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "RDKit WARNING: [19:43:04] Enabling RDKit 2019.09.2 jupyter extensions\n"
    }
   ],
   "source": [
    "# Find all sequences in PDBbind refined dataset from the rcsb dataset\n",
    "# And compare both\n",
    "from collections import defaultdict\n",
    "from os import path\n",
    "import numpy as np\n",
    "from Bio.PDB import PDBParser, PPBuilder\n",
    "from rdkit import Chem\n",
    "\n",
    "PROJECT_FOLDER = \"./\"\n",
    "parser = PDBParser()\n",
    "ppb = PPBuilder()\n",
    "RCSB_SEQUENCES = path.join(PROJECT_FOLDER, \"data/pdb_seqres.txt\")\n",
    "data_dir = path.join(PROJECT_FOLDER, \"data/PDBbind\")\n",
    "refined_dir = path.join(data_dir, \"pdbbind_v2018_refined/refined-set\")\n",
    "index_dir = path.join(data_dir, \"PDBbind_2018_plain_text_index/index\")\n",
    "index_file = path.join(index_dir, \"INDEX_refined_data.2018\")\n",
    "\n",
    "def initialize_dataset_from_index_file():\n",
    "    dataset = []\n",
    "    with open(index_file) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line[0] != \"#\":\n",
    "                dataset.append(line.strip().split())\n",
    "            line = f.readline()\n",
    "    return dataset\n",
    "\n",
    "def get_sequences_from_rcsb(dataset):\n",
    "    sequences = defaultdict(str)\n",
    "    with open(RCSB_SEQUENCES) as file:\n",
    "        pdb_id = file.readline()[1:5]\n",
    "        for data in sorted(dataset):\n",
    "            flg = 0\n",
    "            while pdb_id != data[0]:\n",
    "                file.readline()\n",
    "                pdb_id = file.readline()[1:5]\n",
    "            # Each id can have multiple chains\n",
    "            while pdb_id == data[0]:\n",
    "                flg = 1\n",
    "                seq = file.readline().strip()\n",
    "                sequences[pdb_id] += seq\n",
    "                pdb_id = file.readline()[1:5]\n",
    "            if not flg:\n",
    "                print(pdb_id)\n",
    "    print(len(sequences))\n",
    "    return sequences\n",
    "\n",
    "def get_sequence_from_structure(protein_structure):\n",
    "    sequences = [\n",
    "        str(seq.get_sequence())\n",
    "        for seq in ppb.build_peptides(protein_structure, aa_only=False)\n",
    "    ]\n",
    "    return \"\".join(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/PDBbind/PDBbind_2018_plain_text_index/index/INDEX_refined_data.2018'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c84b07044e85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_dataset_from_index_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sequences_from_rcsb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-4c30657cc2b7>\u001b[0m in \u001b[0;36minitialize_dataset_from_index_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitialize_dataset_from_index_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/PDBbind/PDBbind_2018_plain_text_index/index/INDEX_refined_data.2018'"
     ]
    }
   ],
   "source": [
    "dataset = initialize_dataset_from_index_file()\n",
    "print(dataset[:10])\n",
    "sequences = get_sequences_from_rcsb(dataset)\n",
    "cnt = 0\n",
    "for element in dataset:\n",
    "    pdb_id = element[0]\n",
    "    pdb_prefix = path.join(refined_dir, pdb_id, pdb_id)\n",
    "    protein_structure = parser.get_structure(\n",
    "        pdb_id, pdb_prefix + \"_protein.pdb\"\n",
    "    )\n",
    "    sequence = get_sequence_from_structure(protein_structure)\n",
    "    if sequences[pdb_id] != sequence:\n",
    "        cnt += 1\n",
    "        # print(sequences[pdb_id], sequence)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10mh_1\n{'PHE18': 42, 'ALA19': 43, 'PHE24': 48, 'ASN304': 328, 'VAL306': 330, 'HOH340': 355, 'GLY20': 44, 'SER305': 329, 'GLY78': 102, 'LEU21': 45, 'GLY22': 46, 'GLY23': 47, 'HOH331': 353, 'TYR285': 309, 'PRO80': 104, 'GLU40': 64, 'TRP41': 65, 'ASP42': 66, 'ASP60': 84, 'ILE61': 85, 'LEU100': 124, 'ASN39': 63}\n"
    }
   ],
   "source": [
    "# Testing preprocessing of sc-pdb\n",
    "from os import path, listdir\n",
    "from biopandas.mol2 import PandasMol2\n",
    "from collections import defaultdict\n",
    "from constants import THREE_TO_ONE\n",
    "FOLDER = \"./data/scPDB/raw\"\n",
    "\n",
    "def get_aa_location(res_name, res_id):\n",
    "    aa = THREE_TO_ONE[res_name[:3]]\n",
    "    offset = int(res_name[3:]) - int(res_id) + 1\n",
    "    \n",
    "\n",
    "for i, pdb_id in enumerate(sorted(listdir(FOLDER))):\n",
    "    print(pdb_id)\n",
    "    pmol = PandasMol2().read_mol2(path.join(FOLDER, pdb_id, \"protein.mol2\"))\n",
    "    lmol = PandasMol2().read_mol2(path.join(FOLDER, pdb_id, \"ligand.mol2\"))\n",
    "    ligand_coords = lmol.df[lmol.df['atom_type'] != 'H'][['x', 'y', 'z']]\n",
    "    protein_heavy = pmol.df[pmol.df['atom_type'] != 'H']\n",
    "    binding_site = {}\n",
    "    for j, atom_coord in enumerate(ligand_coords.values):\n",
    "        pmol.df[\"distances\"] = pmol.distance_df(protein_heavy, atom_coord)\n",
    "        cutoff = pmol.df[pmol.df[\"distances\"] <= 4.5]\n",
    "        for k, aa in enumerate(cutoff.values):\n",
    "            binding_site[aa[7]] = aa[6]\n",
    "        # print(cutoff['subst_name'])\n",
    "    print(binding_site)\n",
    "    # if i == 4:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "14274\n15860\n16612\n16341\n15860\n16776\n"
    }
   ],
   "source": [
    "# Checking statistics of the cross-validation splits\n",
    "from os import path, listdir\n",
    "from collections import defaultdict\n",
    "FOLDER = \"./data/scPDB/\"\n",
    "\n",
    "folds = []\n",
    "for i in range(10):\n",
    "    with open(path.join(FOLDER, \"splits\", \"train_ids_fold\" + str(i))) as f:\n",
    "        folds.append(set([line.strip() for line in f.readlines()]))\n",
    "\n",
    "all = folds[0].union(folds[1])\n",
    "print(len(folds[0]))\n",
    "print(len(all))\n",
    "\n",
    "available = defaultdict(set)\n",
    "for file in listdir(path.join(FOLDER, \"raw\")):\n",
    "    available[file[:4]].add(file)\n",
    "\n",
    "print(len(available))\n",
    "with open(path.join(FOLDER, \"splits\", \"scPDB_blacklist.txt\")) as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        available[line[:4]].remove(line)\n",
    "        if available[line[:4]] == set():\n",
    "            del available[line[:4]]\n",
    "\n",
    "with open(path.join(FOLDER, \"splits\", \"scPDB_leakage.txt\")) as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        available[line[:4]].remove(line)\n",
    "        if available[line[:4]] == []:\n",
    "            del available[line[:4]]\n",
    "print(len(available))\n",
    "\n",
    "for key in set(available.keys()) - all:\n",
    "    del available[key]\n",
    "\n",
    "print(len(available))\n",
    "\n",
    "cnt = 0\n",
    "for key, val in available.items():\n",
    "    cnt += len(val)\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "source": [
    "# Convert all mol2 files to pdb files in the raw data\n",
    "from os import system, path, listdir\n",
    "\n",
    "FOLDER = \"./data/scPDB/raw\"\n",
    "\n",
    "for pdb_id in sorted(listdir(FOLDER)):\n",
    "    # print(pdb_id)\n",
    "    err = system(\n",
    "        \"obabel -imol2 \"\n",
    "        + path.join(FOLDER, pdb_id, \"protein.mol2\")\n",
    "        + \" -opdb -O \"\n",
    "        + path.join(FOLDER, pdb_id, \"converted_protein.pdb\")\n",
    "    )\n",
    "    if err != 0:\n",
    "        print(pdb_id)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1bmf_3\n1bmf_4\n1cer_5\n1e1c_1\n1e1q_1\n1e1q_4\n1e79_1\n1e79_4\n1ea0_1\n1h5q_2\n1h6v_1\n1h6v_6\n1h8h_1\n1h8h_4\n1ht2_4\n1k5d_3\n1kfl_6\n1llu_8\n1mx0_1\n1nbm_1\n1nbm_4\n1nvm_3\n1ofd_1\n1ofe_2\n1ohh_3\n1on3_2\n1q3s_2\n1qvr_2\n1qzf_2\n1qzf_7\n1req_1\n1rfu_11\n1rfu_4\n1ryw_5\n1s20_4\n1s3s_1\n1s4d_11\n1sej_9\n1sxj_1\n1sxj_5\n1tf7_4\n1u9i_4\n1w0k_1\n1w88_1\n1xjn_4\n1xjn_6\n1zm4_3\n2buf_18\n2c12_2\n2c2b_1\n2cfy_2\n2ck3_1\n2g82_7\n2gbl_10\n2h12_2\n2j3n_1\n2j3n_4\n2j4l_6\n2nu9_1\n2ome_1\n2qfx_6\n2v7q_1\n2v7q_4\n2vig_5\n2vig_6\n2wbb_1\n2wbd_6\n2wgg_5\n2x06_8\n2xka_4\n3dxj_2\n"
    }
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}